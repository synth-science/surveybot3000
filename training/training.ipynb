{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutli-Staged Training Procedure for Synthetic Item Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, InputExample, util\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datasets import Dataset, load_dataset\n",
    "from IPython.display import display, Markdown\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "config_path = 'config.yaml'\n",
    "\n",
    "with open(config_path, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the base model\n",
    "A list of suitable base models can be found the [SBERT website](https://www.sbert.net/docs/pretrained_models.html). This research utilized the `all-mpnet-base-v2` model. More models can be found on the [huggingface model hub](https://huggingface.co/models). Note that the script requires sentence transformer models (bi-encoder architecture models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nlp/env/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "base_model = SentenceTransformer(\n",
    "    model_name_or_path=config['base_model_path'],\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 - Polarity Calibration\n",
    "Loads a natural language inference (nli) dataset from the huggingface dataset hub ([i.e., the `snli`-dataset](https://huggingface.co/datasets/snli)). The dataset is used to create a synthetic (augmented dataset) in an attempt to teach the model to produce sentence embeddings that will exhibit negative cosine similarities for texts that contain contradictive information. A more sophisticated method to achieve this is described in Opitz & Frank (2022).\n",
    "\n",
    "Opitz, J., & Frank, A. (2022). SBERT studies Meaning Representations: Decomposing Sentence Embeddings into Explainable Semantic Features (arXiv:2206.07023). arXiv. https://doi.org/10.48550/arXiv.2206.07023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Natural Language Inference dataset (Preview)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398119</th>\n",
       "      <td>A man is cutting wood with a power tool.</td>\n",
       "      <td>A man is using a power tool to cut metal.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76379</th>\n",
       "      <td>a man wearing black pants and a red shirt doin...</td>\n",
       "      <td>A man is at the park, doing tricks on his bike.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530523</th>\n",
       "      <td>There are four boys playing soccer, but not al...</td>\n",
       "      <td>Some children are playing a ball game.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255625</th>\n",
       "      <td>A dog with a stick in its mouth climbs out of ...</td>\n",
       "      <td>A dog is hunting.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130058</th>\n",
       "      <td>A farmhand in training points over the barrier...</td>\n",
       "      <td>The farmhand is a man.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence1  \\\n",
       "398119           A man is cutting wood with a power tool.   \n",
       "76379   a man wearing black pants and a red shirt doin...   \n",
       "530523  There are four boys playing soccer, but not al...   \n",
       "255625  A dog with a stick in its mouth climbs out of ...   \n",
       "130058  A farmhand in training points over the barrier...   \n",
       "\n",
       "                                              sentence2          label  \n",
       "398119        A man is using a power tool to cut metal.  contradiction  \n",
       "76379   A man is at the park, doing tricks on his bike.     entailment  \n",
       "530523           Some children are playing a ball game.     entailment  \n",
       "255625                                A dog is hunting.  contradiction  \n",
       "130058                           The farmhand is a man.        neutral  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8614ae6c717d4bc382e8ad9648caec5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Training data for Polarity Calibration (Preview)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man is cutting wood with a power tool.</td>\n",
       "      <td>A man is using a power tool to cut metal.</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>-0.781675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a man wearing black pants and a red shirt doin...</td>\n",
       "      <td>A man is at the park, doing tricks on his bike.</td>\n",
       "      <td>entailment</td>\n",
       "      <td>0.782243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There are four boys playing soccer, but not al...</td>\n",
       "      <td>Some children are playing a ball game.</td>\n",
       "      <td>entailment</td>\n",
       "      <td>0.464564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A dog with a stick in its mouth climbs out of ...</td>\n",
       "      <td>A dog is hunting.</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>-0.356073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A farmhand in training points over the barrier...</td>\n",
       "      <td>The farmhand is a man.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.554376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0           A man is cutting wood with a power tool.   \n",
       "1  a man wearing black pants and a red shirt doin...   \n",
       "2  There are four boys playing soccer, but not al...   \n",
       "3  A dog with a stick in its mouth climbs out of ...   \n",
       "4  A farmhand in training points over the barrier...   \n",
       "\n",
       "                                         sentence2          label     score  \n",
       "0        A man is using a power tool to cut metal.  contradiction -0.781675  \n",
       "1  A man is at the park, doing tricks on his bike.     entailment  0.782243  \n",
       "2           Some children are playing a ball game.     entailment  0.464564  \n",
       "3                                A dog is hunting.  contradiction -0.356073  \n",
       "4                           The farmhand is a man.        neutral  0.554376  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nli_data = load_dataset('snli')\n",
    "\n",
    "df = nli_data['train'].to_pandas()\n",
    "df = df.rename(columns={'premise': 'sentence1', 'hypothesis': 'sentence2'})\n",
    "df['label'] = df['label'].replace({0: 'entailment', 1: 'neutral', 2: 'contradiction'})\n",
    "df = df.sample(frac=1, random_state=420)\n",
    "\n",
    "'''\n",
    "note: for demonstration purposes the dataset is restricted to 200 cases.\n",
    "Comment out the following line to use the full dataset in training\n",
    "'''\n",
    "df = df.head(200)\n",
    "\n",
    "display(Markdown('#### Natural Language Inference dataset (Preview)'))\n",
    "display(df.head(5))\n",
    "\n",
    "def similarity_from_nli(example):\n",
    "    \n",
    "    sentence1 = example['sentence1']\n",
    "    sentence2 = example['sentence2']\n",
    "    label = example['label']\n",
    "    sign = -1 if label == 'contradiction' else 1\n",
    "\n",
    "    embeddings = base_model.encode([sentence1, sentence2], convert_to_tensor=True, batch_size=2000)\n",
    "    \n",
    "    sentence1_embedding = embeddings[0]\n",
    "    sentence2_embedding = embeddings[1]\n",
    "    similarity = util.pytorch_cos_sim(sentence1_embedding, sentence2_embedding).item()\n",
    "    score = similarity * sign\n",
    "\n",
    "    return {\n",
    "        'sentence1': sentence1,\n",
    "        'sentence2': sentence2,\n",
    "        'score': score\n",
    "    }\n",
    "\n",
    "train_dataset = Dataset.from_pandas(df, preserve_index=False)\n",
    "train_dataset = train_dataset.map(similarity_from_nli)\n",
    "\n",
    "display(Markdown('#### Training data for Polarity Calibration (Preview)'))\n",
    "display(train_dataset.to_pandas().head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training (Polarity Calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5cc744cdc1462a845f0a653a3ab396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b046597e07d8430ab79727184447a032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe3a2ea73d9a4e9ab7220f982b8bbfe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_examples = [\n",
    "    InputExample(\n",
    "        texts=[sentence1, sentence2],\n",
    "        label=score\n",
    "    ) \n",
    "    for sentence1, sentence2, score in zip(\n",
    "        train_dataset['sentence1'],\n",
    "        train_dataset['sentence2'], \n",
    "        train_dataset['score']\n",
    "    )\n",
    "]\n",
    "\n",
    "train_loss = CosineSimilarityLoss(base_model)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    input_examples,\n",
    "    batch_size=config['polarity_calibration']['batch_size'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "warmup_steps = math.ceil(len(train_dataloader) * config['polarity_calibration']['num_epochs'] * 0.1)\n",
    "\n",
    "'''\n",
    "optional: use the EmbeddingSimilarityEvaluator-class to evaluate model performance to \n",
    "a) evaluate performance during training (validation_evaluator)\n",
    "b) evaluate performance after training is completed (test_evaluator)\n",
    "\n",
    "note that using evaluators relies on cross validation (train-validation-test-splitting)\n",
    "\n",
    "'''\n",
    "# from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "# validation_evaluator = EmbeddingSimilarityEvaluator(sentence1, sentence2, scores)\n",
    "# test_evaluator = EmbeddingSimilarityEvaluator(sentence1, sentence2, scores)\n",
    "\n",
    "base_model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=config['polarity_calibration']['num_epochs'],    \n",
    "    optimizer_params={\n",
    "        'lr': float(config['polarity_calibration']['learning_rate'])\n",
    "    },\n",
    "    weight_decay=float(config['polarity_calibration']['weight_decay']),\n",
    "    warmup_steps=warmup_steps,\n",
    "    # evaluator=validation_evaluator,\n",
    "    # evaluation_steps=config['polarity_calibration']['evaluation_steps'],\n",
    "    output_path=config['save_model_path'],\n",
    "    save_best_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 - Domain Adaptation\n",
    "In this stage, we use `CosineSimilarityLoss` to teach the model that similarity is defined by the observed item correlation, obtained from various empirical sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the previously calibrated model\n",
    "**Important**: To save GPU memory, do not run the entire script but each training stage independently! You may want to restart the notebook at before running this section (do not forget to run setup and imports in that case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_model = SentenceTransformer(\n",
    "    model_name_or_path=config['save_model_path'],\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training (Domain Adaptation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Dataset for Domain Adaptation (Preview)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_a</th>\n",
       "      <th>item_b</th>\n",
       "      <th>correlation</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>i am good at many things.</td>\n",
       "      <td>i find it hard to forgive others.</td>\n",
       "      <td>-0.010869</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>i am often in a bad mood.</td>\n",
       "      <td>i want to be left alone.</td>\n",
       "      <td>0.282357</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>i find political discussions interesting.</td>\n",
       "      <td>i am happy with my life.</td>\n",
       "      <td>0.085023</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>i always know what i am doing.</td>\n",
       "      <td>i usually enjoy being with people.</td>\n",
       "      <td>0.071936</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>i love to be the center of attention.</td>\n",
       "      <td>i am under constant pressure.</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         item_a  \\\n",
       "1742                  i am good at many things.   \n",
       "524                   i am often in a bad mood.   \n",
       "630   i find political discussions interesting.   \n",
       "382              i always know what i am doing.   \n",
       "971       i love to be the center of attention.   \n",
       "\n",
       "                                  item_b  correlation partition  \n",
       "1742   i find it hard to forgive others.    -0.010869     train  \n",
       "524             i want to be left alone.     0.282357     train  \n",
       "630             i am happy with my life.     0.085023     train  \n",
       "382   i usually enjoy being with people.     0.071936     train  \n",
       "971        i am under constant pressure.     0.006074     train  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0206218085c476db919aae646862ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e5d5f9c8964abd957574cfb544abbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad09aef82584d27b133984f806cb6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b41808afa2a4b56a08cadb2dfd642f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf50852611549cbae91f583fa9f3b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4d16317c934775926a7a5202847f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd97dab38a724065a0b84a6085592d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9924515d233e4e4bb9e20e18412b4aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820a610e292c4e068a5843f4c6fa825f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(filepath_or_buffer='train_domain-adaptation.csv').sample(frac=1, random_state=420)\n",
    "\n",
    "display(Markdown('#### Dataset for Domain Adaptation (Preview)'))\n",
    "display(df.head(5))\n",
    "\n",
    "training_data = df.query('partition == \"train\"')\n",
    "validation_data = df.query('partition == \"dev\"')\n",
    "test_data = df.query('partition == \"test\"')\n",
    "\n",
    "validation_evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=validation_data['item_a'].tolist(),\n",
    "    sentences2=validation_data['item_b'].tolist(),\n",
    "    scores=validation_data['correlation'].tolist()\n",
    ")\n",
    "\n",
    "test_evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=test_data['item_a'].tolist(),\n",
    "    sentences2=test_data['item_b'].tolist(),\n",
    "    scores=test_data['correlation'].tolist()\n",
    ")\n",
    "\n",
    "input_examples = [\n",
    "    InputExample(\n",
    "        texts=[sentence1, sentence2],\n",
    "        label=score\n",
    "    ) \n",
    "    for sentence1, sentence2, score in zip(\n",
    "        training_data['item_a'],\n",
    "        training_data['item_b'], \n",
    "        training_data['correlation']\n",
    "    )\n",
    "]\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=input_examples,\n",
    "    shuffle=True,\n",
    "    batch_size=config['domain_adaptation']['batch_size']\n",
    ")\n",
    "\n",
    "warmup_steps = math.ceil(len(train_dataloader) * config['domain_adaptation']['num_epochs'] * 0.1)\n",
    "\n",
    "n_layers = len(calibrated_model[0].auto_model.encoder.layer)\n",
    "n_freeze = math.ceil(.15 * n_layers)\n",
    "regex_pattern = f'0\\.auto_model\\.encoder\\.layer\\.[0-{n_freeze}]\\..+'\n",
    "\n",
    "for name, param in calibrated_model.named_parameters():\n",
    "    param.requires_grad = (re.match(regex_pattern, name) is None)\n",
    "\n",
    "train_loss = CosineSimilarityLoss(calibrated_model)\n",
    "\n",
    "calibrated_model.fit(\n",
    "        train_objectives=[(train_dataloader, train_loss)],\n",
    "        evaluator=validation_evaluator,\n",
    "        epochs=int(config['domain_adaptation']['num_epochs']),\n",
    "        evaluation_steps=int(config['domain_adaptation']['evaluation_steps']),\n",
    "        optimizer_params={\n",
    "            'lr': float(config['domain_adaptation']['learning_rate'])\n",
    "        },\n",
    "        weight_decay=float(config['domain_adaptation']['weight_decay']),\n",
    "        warmup_steps=warmup_steps,\n",
    "        output_path=config['save_model_path'],\n",
    "        save_best_model=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Validation-set Evaluation: 0.48"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Test-set Evaluation: 0.36"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f'#### Validation-set Evaluation: {np.round(calibrated_model.evaluate(validation_evaluator), 2)}'))\n",
    "display(Markdown(f'#### Test-set Evaluation: {np.round(calibrated_model.evaluate(test_evaluator), 2)}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Model\n",
    "Save the model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrated_model.save('enter_model_save_path_here')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
